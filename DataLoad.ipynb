{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Reminder - use daily log to track progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "#import torch\n",
    "import IPython.display as ipd\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo apt-get install wget unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data\n",
    "#!mkdir -p data && cd data && wget https://irmas-dataset.s3-eu-west-1.amazonaws.com/IRMAS-TrainingData.zip && unzip IRMAS-TrainingData.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download testing data (Around 2GB each)\n",
    "#wget https://irmas-dataset.s3-eu-west-1.amazonaws.com/IRMAS-TestingData-Part1.zip && IRMAS-TestingData-Part1.zip\n",
    "#wget https://irmas-dataset.s3-eu-west-1.amazonaws.com/IRMAS-TestingData-Part2.zip && IRMAS-TestingData-Part2.zip\n",
    "#wget https://irmas-dataset.s3-eu-west-1.amazonaws.com/IRMAS-TestingData-Part3.zip && IRMAS-TestingData-Part3.zip    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRMAS dataset (training)\n",
    " \n",
    "Audio files: 6705 audio files in 16 bit stereo wav format sampled at 44.1kHz. They are excerpts of 3 seconds from more than 2000 distinct recordings. \n",
    "\n",
    "Annotations: The annotation of the predominant instrument of each excerpt is both in the name of the containing folder, and in the file name: cello (cel), clarinet (cla), flute (flu), acoustic guitar (gac), electric guitar (gel), organ (org), piano (pia), saxophone (sax), trumpet (tru), violin (vio), and human singing voice (voi). The number of files per instrument are: cel(388), cla(505), flu(451), gac(637), gel(760), org(682), pia(721), sax(626), tru(577), vio(580), voi(778). \n",
    "\n",
    "Additionally, some of the files have annotations in the filename regarding the presence ([dru]) or non presence([nod]) of drums, and the musical genre: country-folk ([cou_fol]), classical ([cla]), pop-rock ([pop-roc]), latin-soul ([lat-sou])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>wav_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sax</td>\n",
       "      <td>data/IRMAS-TrainingData/sax/[sax][jaz_blu]1783...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flu</td>\n",
       "      <td>data/IRMAS-TrainingData/flu/024__[flu][nod][cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>org</td>\n",
       "      <td>data/IRMAS-TrainingData/org/[org][pop_roc]1264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>org</td>\n",
       "      <td>data/IRMAS-TrainingData/org/[org][jaz_blu]1154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sax</td>\n",
       "      <td>data/IRMAS-TrainingData/sax/010__[sax][nod][cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tags                                           wav_path\n",
       "0  sax  data/IRMAS-TrainingData/sax/[sax][jaz_blu]1783...\n",
       "1  flu  data/IRMAS-TrainingData/flu/024__[flu][nod][cl...\n",
       "2  org  data/IRMAS-TrainingData/org/[org][pop_roc]1264...\n",
       "3  org  data/IRMAS-TrainingData/org/[org][jaz_blu]1154...\n",
       "4  sax  data/IRMAS-TrainingData/sax/010__[sax][nod][cl..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IRMAS_TRAINING = 'data/IRMAS-TrainingData'\n",
    "base_path = pathlib.Path(IRMAS_TRAINING)\n",
    "classes, paths = [], []\n",
    "\n",
    "for p in base_path.glob('*/*'):\n",
    "    relative_path = p.relative_to(base_path)\n",
    "    classes.append(str(relative_path.parent))\n",
    "    paths.append(p)\n",
    "    \n",
    "#classes = set(classes)\n",
    "df = pd.DataFrame({\"tags\": classes, \"wav_path\": paths}).sample(frac=1)#.reset_index(drop=True)#, inplace=True)\n",
    "#df_training.piano = df.tags.map({'pia': True, '': 0})\n",
    "#df.tags = df.tags.map({'pia': True, })\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6705, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cel', 'cla', 'flu', 'gac', 'gel', 'org', 'pia', 'sax', 'tru', 'vio', 'voi'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_labels = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cel', 'sax', 'tru', 'flu', 'gac', 'org', 'vio', 'cla', 'voi', 'pia', 'gel']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inst_dict = {1:'cel', 2:'cla', 3:'flu', 4:'gac', 5:'gel',6:'org',7:'pia',8:'sax',9:'tru',10:'vio',11:'voi'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = set(df.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = set(df.tags)\n",
    "c_list = sorted(list(c_list))\n",
    "c_dict =  { i: c_list[i] for i in range(0, len(c_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'cel',\n",
       " 1: 'cla',\n",
       " 2: 'flu',\n",
       " 3: 'gac',\n",
       " 4: 'gel',\n",
       " 5: 'org',\n",
       " 6: 'pia',\n",
       " 7: 'sax',\n",
       " 8: 'tru',\n",
       " 9: 'vio',\n",
       " 10: 'voi'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_dict = dict(map(reversed, c_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cel': 0,\n",
       " 'cla': 1,\n",
       " 'flu': 2,\n",
       " 'gac': 3,\n",
       " 'gel': 4,\n",
       " 'org': 5,\n",
       " 'pia': 6,\n",
       " 'sax': 7,\n",
       " 'tru': 8,\n",
       " 'vio': 9,\n",
       " 'voi': 10}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = { i: classes[i] for i in range(0, len(classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'cel',\n",
       " 1: 'sax',\n",
       " 2: 'tru',\n",
       " 3: 'flu',\n",
       " 4: 'gac',\n",
       " 5: 'org',\n",
       " 6: 'vio',\n",
       " 7: 'cla',\n",
       " 8: 'voi',\n",
       " 9: 'pia',\n",
       " 10: 'gel'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pia'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4693, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2012, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6705, 0, 6705, 6705)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if files are loading\n",
    "successful, corrupted = [], []\n",
    "len_x, sample_rates = [], []\n",
    "raw_samples, sample_rates = [], []\n",
    "for p in df.wav_path:\n",
    "    try:\n",
    "        x, sr = librosa.load(p, sr=None)\n",
    "        successful.append(p)\n",
    "        len_x.append(len(x))\n",
    "        raw_samples.append(x)\n",
    "        sample_rates.append(sr)\n",
    "    except:\n",
    "        corrupted.append(p)\n",
    "#       print(p)\n",
    "###df = df[~df.wav_path.isin(corrupted)]\n",
    "assert len(successful) == len(raw_samples)\n",
    "len(successful), len(corrupted), len(raw_samples), len(sample_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({132299}, {44100}, 2.9999773242630385)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(len_x), set(sample_rates), 132299/44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>wav_path</th>\n",
       "      <th>raw_sounds</th>\n",
       "      <th>sample_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sax</td>\n",
       "      <td>data/IRMAS-TrainingData/sax/[sax][jaz_blu]1783...</td>\n",
       "      <td>[0.25650024, 0.26246643, 0.26890564, 0.2795105...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flu</td>\n",
       "      <td>data/IRMAS-TrainingData/flu/024__[flu][nod][cl...</td>\n",
       "      <td>[-0.039413452, -0.03929138, -0.038650513, -0.0...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>org</td>\n",
       "      <td>data/IRMAS-TrainingData/org/[org][pop_roc]1264...</td>\n",
       "      <td>[0.015457153, -0.03942871, -0.088027954, -0.13...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>org</td>\n",
       "      <td>data/IRMAS-TrainingData/org/[org][jaz_blu]1154...</td>\n",
       "      <td>[-0.07325745, -0.051971436, -0.009857178, 0.04...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sax</td>\n",
       "      <td>data/IRMAS-TrainingData/sax/010__[sax][nod][cl...</td>\n",
       "      <td>[-0.25881958, -0.28485107, -0.30062866, -0.305...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>vio</td>\n",
       "      <td>data/IRMAS-TrainingData/vio/[vio][cla]2222__1.wav</td>\n",
       "      <td>[-0.08105469, -0.07783508, -0.06806946, -0.055...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>cla</td>\n",
       "      <td>data/IRMAS-TrainingData/cla/[cla][pop_roc]0202...</td>\n",
       "      <td>[0.06440735, 0.10116577, 0.14259338, 0.1802215...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>gel</td>\n",
       "      <td>data/IRMAS-TrainingData/gel/[gel][pop_roc]0879...</td>\n",
       "      <td>[-0.22242737, -0.1726532, -0.12521362, -0.0821...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>org</td>\n",
       "      <td>data/IRMAS-TrainingData/org/[org][jaz_blu]1048...</td>\n",
       "      <td>[-0.07136536, -0.07118225, -0.06903076, -0.070...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>gel</td>\n",
       "      <td>data/IRMAS-TrainingData/gel/031__[gel][dru][po...</td>\n",
       "      <td>[0.054901123, 0.03466797, -0.0050201416, -0.06...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6705 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tags                                           wav_path  \\\n",
       "0     sax  data/IRMAS-TrainingData/sax/[sax][jaz_blu]1783...   \n",
       "1     flu  data/IRMAS-TrainingData/flu/024__[flu][nod][cl...   \n",
       "2     org  data/IRMAS-TrainingData/org/[org][pop_roc]1264...   \n",
       "3     org  data/IRMAS-TrainingData/org/[org][jaz_blu]1154...   \n",
       "4     sax  data/IRMAS-TrainingData/sax/010__[sax][nod][cl...   \n",
       "...   ...                                                ...   \n",
       "6700  vio  data/IRMAS-TrainingData/vio/[vio][cla]2222__1.wav   \n",
       "6701  cla  data/IRMAS-TrainingData/cla/[cla][pop_roc]0202...   \n",
       "6702  gel  data/IRMAS-TrainingData/gel/[gel][pop_roc]0879...   \n",
       "6703  org  data/IRMAS-TrainingData/org/[org][jaz_blu]1048...   \n",
       "6704  gel  data/IRMAS-TrainingData/gel/031__[gel][dru][po...   \n",
       "\n",
       "                                             raw_sounds  sample_rate  \n",
       "0     [0.25650024, 0.26246643, 0.26890564, 0.2795105...        44100  \n",
       "1     [-0.039413452, -0.03929138, -0.038650513, -0.0...        44100  \n",
       "2     [0.015457153, -0.03942871, -0.088027954, -0.13...        44100  \n",
       "3     [-0.07325745, -0.051971436, -0.009857178, 0.04...        44100  \n",
       "4     [-0.25881958, -0.28485107, -0.30062866, -0.305...        44100  \n",
       "...                                                 ...          ...  \n",
       "6700  [-0.08105469, -0.07783508, -0.06806946, -0.055...        44100  \n",
       "6701  [0.06440735, 0.10116577, 0.14259338, 0.1802215...        44100  \n",
       "6702  [-0.22242737, -0.1726532, -0.12521362, -0.0821...        44100  \n",
       "6703  [-0.07136536, -0.07118225, -0.06903076, -0.070...        44100  \n",
       "6704  [0.054901123, 0.03466797, -0.0050201416, -0.06...        44100  \n",
       "\n",
       "[6705 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['raw_sounds'] = raw_samples\n",
    "df_raw['sample_rate'] = sample_rates\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#with open('Data/IRMAS_raw.json', 'w') as f:\n",
    "#    json.dumps(df.T.to_dict(orient='list'), f)\n",
    "#df_raw.to_json('Data/IRMAS_raw.json')\n",
    "#df_raw.to_json('Data/IRMAS_raw.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstrumentClassificationDataset():\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df.copy()\n",
    "#        self.image_transform = image_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sound = self.load_from_disk(index)\n",
    "        label = self.load_label(index)\n",
    "#        Xi = self.image_transform(Xi)\n",
    "        return sound, label\n",
    "\n",
    "    def load_to_librosa(self, path):\n",
    "        image = librosa.load(path)\n",
    "        return image\n",
    "\n",
    "    def load_from_disk(self, index):\n",
    "        wav_path = df.iloc[index].wav_path \n",
    "        return self.load_to_librosa(wav_path)\n",
    "\n",
    "    def load_label(self, index):\n",
    "        label = df.iloc[index].tags\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSampler():\n",
    "    def __init__(self, df, list_of_instruments, n_samples):\n",
    "        self.df = df.copy()\n",
    "        self.n_samples = n_samples\n",
    "        self.instruments = list_of_instruments\n",
    "        #df = df[self.instruments]\n",
    "        df = df[df['tags'].isin(self.instruments)]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self._get_sample())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def _get_samples(self):\n",
    "        return np.random.choice(len(self.df), self.n_samples, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the instruments we are using\n",
    "list_of_instruments = ['sax', 'pia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BaseSampler(df, list_of_instruments, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1091, 5855, 5470, 6028, 5279, 6569,  535, 3214, 1519, 2302, 5579,\n",
       "       3447, 1769, 2187, 1116, 3512, 3527, 5870, 1179, 4101, 1331, 2690,\n",
       "       5172, 1944, 1444, 5553,  530, 5263,  803, 4502])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs._get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = bs._get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = InstrumentClassificationDataset(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sound_generator(df, inst, batch_size = 30):\n",
    "    df = df[df['tags'].isin(inst)].copy()\n",
    "    while True:\n",
    "        batch_x, labels = [], []\n",
    "        batch_index = np.random.choice(len(df), batch_size, replace=False)\n",
    "        for idx in batch_index:\n",
    "            wav_path = df.iloc[idx].wav_path \n",
    "            sound_frame, sr = librosa.load(wav_path, sr=None)\n",
    "            batch_x.append(sound_frame)\n",
    "#            labels.append(df.iloc[idx].tags)\n",
    "            labels.append(inverted_dict[df.iloc[idx].tags])\n",
    "#        batch_x = np.array( batch_x )\n",
    "#        labels = np.array (labels)\n",
    "#        batch_x = np.expand_dims(sounds, axis=2)\n",
    "        batch_x = np.array(batch_x).reshape(len(batch_x), -1, 1)\n",
    "        labels = np.array(labels)\n",
    "        yield( batch_x, labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg  = sound_generator(df_train, list_of_instruments, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = sound_generator(df_test, list_of_instruments, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds, labels = next(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = np.array(sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 132299, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.01150513],\n",
       "        [-0.01174927],\n",
       "        [-0.01403809],\n",
       "        ...,\n",
       "        [ 0.00045776],\n",
       "        [ 0.00141907],\n",
       "        [ 0.00434875]], dtype=float32),\n",
       " 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sounds[1], labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132299,\n",
       " array([-0.32502747], dtype=float32),\n",
       " array([0.3551178], dtype=float32))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sounds[1]), min(sounds[1]), max(sounds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the sounds and labels match \n",
    "#random = randint(0,29)\n",
    "#print(labels[random])\n",
    "#ipd.Audio(sounds[random], rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 132299, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.08622742],\n",
       "        [ 0.07713318],\n",
       "        [ 0.0705719 ],\n",
       "        ...,\n",
       "        [ 0.14024353],\n",
       "        [ 0.12420654],\n",
       "        [ 0.11634827]],\n",
       "\n",
       "       [[-0.01150513],\n",
       "        [-0.01174927],\n",
       "        [-0.01403809],\n",
       "        ...,\n",
       "        [ 0.00045776],\n",
       "        [ 0.00141907],\n",
       "        [ 0.00434875]],\n",
       "\n",
       "       [[ 0.13269043],\n",
       "        [ 0.08795166],\n",
       "        [ 0.03756714],\n",
       "        ...,\n",
       "        [-0.14596558],\n",
       "        [-0.1451416 ],\n",
       "        [-0.14480591]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.01373291],\n",
       "        [-0.01483154],\n",
       "        [-0.01660156],\n",
       "        ...,\n",
       "        [-0.00575256],\n",
       "        [-0.00535583],\n",
       "        [-0.0050354 ]],\n",
       "\n",
       "       [[-0.10081482],\n",
       "        [-0.1038208 ],\n",
       "        [-0.09669495],\n",
       "        ...,\n",
       "        [ 0.04333496],\n",
       "        [ 0.04457092],\n",
       "        [ 0.04475403]],\n",
       "\n",
       "       [[-0.03660583],\n",
       "        [-0.04147339],\n",
       "        [-0.04570007],\n",
       "        ...,\n",
       "        [-0.01412964],\n",
       "        [-0.01449585],\n",
       "        [-0.01477051]]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 132299, 1, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.expand_dims(sounds, axis=2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 132280, 32)        672       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 33070, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 33051, 64)         41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 8262, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 8243, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 2060, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 263680)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               26368100  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 11)                1111      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 26,574,875\n",
      "Trainable params: 26,574,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "#model.add(layers.Conv1D(1, kernel_size = 200, input_shape=(13299,1))) #\n",
    "model.add(layers.Conv1D(filters = 32, kernel_size=20, activation='relu', input_shape=(132299,1,)))\n",
    "model.add(layers.MaxPooling1D(pool_size=4))\n",
    "model.add(layers.Conv1D(filters = 64, kernel_size=20, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=4))\n",
    "model.add(layers.Conv1D(filters = 128, kernel_size=20, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=4))\n",
    "#model.add(LSTM(64))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(amount_of_labels))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-774ba6c7e5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    607\u001b[0m   \u001b[0;31m# As a fallback for the data type that does not work with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[0;31m# _standardize_user_data, use the _prepare_model_with_inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0mnested_dtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0mnested_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_shape_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;31m# Note that dataset API takes a callable that creates a generator object,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0mnested_dtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0mnested_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_shape_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;31m# Note that dataset API takes a callable that creates a generator object,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    sg,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=20,\n",
    "    validation_data=tg,\n",
    "    validation_steps=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1025\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: Expecting int64_t value for attr strides, got numpy.int32",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-d4920c332cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'causal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m   1132\u001b[0m           call_from_convolution=False)\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# copybara:strip_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv1d\u001b[0;34m(self, input, filter, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;31m# pylint: enable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1682\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspatial_start_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   1032\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_eager_fallback\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[1;32m   1128\u001b[0m   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[1;32m   1129\u001b[0m   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1130\u001b[0;31m                              ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m   1131\u001b[0m   _execute.record_gradient(\n\u001b[1;32m   1132\u001b[0m       \"Conv2D\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/keras_cpu/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    sg,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=10,\n",
    "    validation_data=tg,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model.history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(model.history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(model.history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(model.history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr-dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
